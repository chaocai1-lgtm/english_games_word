# -*- coding: utf-8 -*-
"""
Neo4j æ•°æ®åº“å¯¼å…¥è„šæœ¬
å°†è§£æåçš„å•è¯æ•°æ®å¯¼å…¥åˆ° Neo4j å›¾æ•°æ®åº“
"""

import os
from neo4j import GraphDatabase
from dotenv import load_dotenv
from word_parser import WordParser, Word
from typing import List


class Neo4jWordImporter:
    """Neo4j å•è¯æ•°æ®å¯¼å…¥å™¨"""
    
    def __init__(self):
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        self.uri = os.getenv("NEO4J_URI")
        self.username = os.getenv("NEO4J_USERNAME")
        self.password = os.getenv("NEO4J_PASSWORD")
        
        if not all([self.uri, self.username, self.password]):
            raise ValueError("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® Neo4j è¿æ¥ä¿¡æ¯")
        
        self.driver = None
        
    def connect(self):
        """è¿æ¥åˆ° Neo4j æ•°æ®åº“"""
        try:
            # ä¸º Neo4j Aura äº‘æœåŠ¡æ·»åŠ å¿…è¦çš„é…ç½®
            self.driver = GraphDatabase.driver(
                self.uri, 
                auth=(self.username, self.password),
                max_connection_lifetime=3600,
                max_connection_pool_size=50,
                connection_acquisition_timeout=60
            )
            # éªŒè¯è¿æ¥ - ä½¿ç”¨ç®€å•æŸ¥è¯¢è€Œä¸æ˜¯ verify_connectivity
            with self.driver.session() as session:
                result = session.run("RETURN 1 AS test")
                result.single()
            print("âœ… Neo4j è¿æ¥æˆåŠŸ!")
            return True
        except Exception as e:
            print(f"âŒ Neo4j è¿æ¥å¤±è´¥: {e}")
            print(f"URI: {self.uri}")
            print(f"Username: {self.username}")
            print("æç¤º: è¯·ç¡®ä¿ Neo4j Aura æ•°æ®åº“æ­£åœ¨è¿è¡Œï¼Œä¸”ç½‘ç»œè¿æ¥æ­£å¸¸")
            return False
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.driver:
            self.driver.close()
            print("Neo4j è¿æ¥å·²å…³é—­")
    
    def clear_database(self):
        """æ¸…ç©ºæ•°æ®åº“ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰"""
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
            print("âš ï¸ æ•°æ®åº“å·²æ¸…ç©º")
    
    def create_constraints(self):
        """åˆ›å»ºçº¦æŸå’Œç´¢å¼•"""
        constraints = [
            "CREATE CONSTRAINT word_unique IF NOT EXISTS FOR (w:Word) REQUIRE w.word IS UNIQUE",
            "CREATE CONSTRAINT grade_unique IF NOT EXISTS FOR (g:Grade) REQUIRE g.name IS UNIQUE",
            "CREATE CONSTRAINT root_unique IF NOT EXISTS FOR (r:Root) REQUIRE r.name IS UNIQUE",
            "CREATE CONSTRAINT user_unique IF NOT EXISTS FOR (u:User) REQUIRE u.id IS UNIQUE",
        ]
        
        with self.driver.session() as session:
            for constraint in constraints:
                try:
                    session.run(constraint)
                except Exception as e:
                    print(f"çº¦æŸåˆ›å»ºè·³è¿‡ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")
            
            print("âœ… çº¦æŸå’Œç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    def import_grades(self):
        """å¯¼å…¥å¹´çº§èŠ‚ç‚¹"""
        grades = [
            {"name": "7å¹´çº§ä¸Šå†Œ", "level": 1, "floor_start": 1, "floor_end": 2},
            {"name": "7å¹´çº§ä¸‹å†Œ", "level": 2, "floor_start": 2, "floor_end": 3},
            {"name": "8å¹´çº§ä¸Šå†Œ", "level": 3, "floor_start": 4, "floor_end": 5},
            {"name": "8å¹´çº§ä¸‹å†Œ", "level": 4, "floor_start": 5, "floor_end": 6},
            {"name": "9å¹´çº§", "level": 5, "floor_start": 7, "floor_end": 9},
        ]
        
        query = """
        UNWIND $grades AS grade
        MERGE (g:Grade {name: grade.name})
        SET g.level = grade.level,
            g.floor_start = grade.floor_start,
            g.floor_end = grade.floor_end
        """
        
        with self.driver.session() as session:
            session.run(query, grades=grades)
            print(f"âœ… å¯¼å…¥ {len(grades)} ä¸ªå¹´çº§èŠ‚ç‚¹")
    
    def import_roots(self, roots: List[str]):
        """å¯¼å…¥è¯æ ¹èŠ‚ç‚¹"""
        root_data = [{"name": r} for r in roots if r]
        
        if not root_data:
            return
        
        query = """
        UNWIND $roots AS root
        MERGE (r:Root {name: root.name})
        """
        
        with self.driver.session() as session:
            session.run(query, roots=root_data)
            print(f"âœ… å¯¼å…¥ {len(root_data)} ä¸ªè¯æ ¹èŠ‚ç‚¹")
    
    def import_words(self, words: List[Word], batch_size: int = 100):
        """æ‰¹é‡å¯¼å…¥å•è¯èŠ‚ç‚¹"""
        word_data = [w.to_dict() for w in words]
        
        # åˆ›å»ºå•è¯èŠ‚ç‚¹
        create_word_query = """
        UNWIND $words AS w
        MERGE (word:Word {word: w.word})
        SET word.phonetic = w.phonetic,
            word.pos = w.pos,
            word.definition = w.definition,
            word.page = w.page,
            word.difficulty = w.difficulty,
            word.is_phrase = w.is_phrase,
            word.mastered_count = 0,
            word.wrong_count = 0
        """
        
        # å»ºç«‹å•è¯ä¸å¹´çº§çš„å…³ç³»
        grade_relation_query = """
        UNWIND $words AS w
        MATCH (word:Word {word: w.word})
        MATCH (grade:Grade {name: w.grade})
        MERGE (word)-[:BELONGS_TO]->(grade)
        """
        
        # å»ºç«‹å•è¯ä¸è¯æ ¹çš„å…³ç³»
        root_relation_query = """
        UNWIND $words AS w
        MATCH (word:Word {word: w.word})
        WHERE w.root IS NOT NULL AND w.root <> ''
        MATCH (root:Root {name: w.root})
        MERGE (word)-[:HAS_ROOT]->(root)
        """
        
        with self.driver.session() as session:
            # åˆ†æ‰¹å¯¼å…¥
            for i in range(0, len(word_data), batch_size):
                batch = word_data[i:i + batch_size]
                session.run(create_word_query, words=batch)
                print(f"  å¯¼å…¥å•è¯: {i + len(batch)}/{len(word_data)}")
            
            # å»ºç«‹å¹´çº§å…³ç³»
            for i in range(0, len(word_data), batch_size):
                batch = word_data[i:i + batch_size]
                session.run(grade_relation_query, words=batch)
            
            # å»ºç«‹è¯æ ¹å…³ç³»
            words_with_root = [w for w in word_data if w.get('root')]
            if words_with_root:
                session.run(root_relation_query, words=words_with_root)
        
        print(f"âœ… å¯¼å…¥ {len(words)} ä¸ªå•è¯èŠ‚ç‚¹åŠå…³ç³»")
    
    def create_same_root_relations(self):
        """åˆ›å»ºåŒè¯æ ¹å•è¯ä¹‹é—´çš„å…³ç³»"""
        query = """
        MATCH (w1:Word)-[:HAS_ROOT]->(r:Root)<-[:HAS_ROOT]-(w2:Word)
        WHERE id(w1) < id(w2)
        MERGE (w1)-[:SAME_ROOT {root: r.name}]->(w2)
        """
        
        with self.driver.session() as session:
            result = session.run(query)
            print("âœ… åˆ›å»ºåŒè¯æ ¹å…³ç³»å®Œæˆ")
    
    def create_difficulty_floor_mapping(self):
        """åˆ›å»ºéš¾åº¦ä¸æ¥¼å±‚çš„æ˜ å°„"""
        query = """
        // åˆ›å»ºæ¥¼å±‚èŠ‚ç‚¹
        UNWIND range(1, 9) AS floor_num
        MERGE (f:Floor {number: floor_num})
        SET f.difficulty = CASE 
            WHEN floor_num <= 3 THEN 1
            WHEN floor_num <= 5 THEN 2
            WHEN floor_num <= 7 THEN 3
            ELSE 4
        END
        """
        
        with self.driver.session() as session:
            session.run(query)
            print("âœ… åˆ›å»ºæ¥¼å±‚èŠ‚ç‚¹å®Œæˆ")
    
    def get_statistics(self) -> dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        queries = {
            "words": "MATCH (w:Word) RETURN count(w) AS count",
            "grades": "MATCH (g:Grade) RETURN count(g) AS count",
            "roots": "MATCH (r:Root) RETURN count(r) AS count",
            "belongs_to": "MATCH ()-[r:BELONGS_TO]->() RETURN count(r) AS count",
            "has_root": "MATCH ()-[r:HAS_ROOT]->() RETURN count(r) AS count",
            "same_root": "MATCH ()-[r:SAME_ROOT]->() RETURN count(r) AS count",
        }
        
        stats = {}
        with self.driver.session() as session:
            for key, query in queries.items():
                result = session.run(query).single()
                stats[key] = result["count"] if result else 0
        
        return stats


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå®Œæ•´çš„æ•°æ®å¯¼å…¥æµç¨‹"""
    print("=" * 60)
    print("å•è¯é­”å¡”æ¢é™© - Neo4j æ•°æ®å¯¼å…¥")
    print("=" * 60)
    
    # 1. è§£æå•è¯æ–‡ä»¶
    current_dir = os.path.dirname(os.path.abspath(__file__))
    word_file = os.path.join(current_dir, "æ‰€æœ‰å•è¯.txt")
    
    if not os.path.exists(word_file):
        print(f"âŒ æ‰¾ä¸åˆ°å•è¯æ–‡ä»¶: {word_file}")
        return
    
    print("\nğŸ“– æ­£åœ¨è§£æå•è¯æ–‡ä»¶...")
    parser = WordParser(word_file)
    words = parser.parse()
    
    stats = parser.get_statistics()
    print(f"  è§£æå®Œæˆ: {stats['total']} ä¸ªè¯æ¡")
    print(f"  å•è¯: {stats['single_words']}, çŸ­è¯­: {stats['phrases']}")
    print(f"  è¯†åˆ«è¯æ ¹: {stats['roots_identified']} ç§")
    
    # 2. è¿æ¥ Neo4j
    print("\nğŸ”Œ æ­£åœ¨è¿æ¥ Neo4j...")
    importer = Neo4jWordImporter()
    
    if not importer.connect():
        return
    
    try:
        # 3. æ¸…ç©ºå¹¶é‡å»ºæ•°æ®åº“
        print("\nğŸ—‘ï¸ æ¸…ç©ºç°æœ‰æ•°æ®...")
        importer.clear_database()
        
        # 4. åˆ›å»ºçº¦æŸ
        print("\nğŸ“ åˆ›å»ºçº¦æŸå’Œç´¢å¼•...")
        importer.create_constraints()
        
        # 5. å¯¼å…¥å¹´çº§
        print("\nğŸ“š å¯¼å…¥å¹´çº§æ•°æ®...")
        importer.import_grades()
        
        # 6. å¯¼å…¥è¯æ ¹
        print("\nğŸŒ± å¯¼å…¥è¯æ ¹æ•°æ®...")
        roots = parser.get_all_roots()
        importer.import_roots(roots)
        
        # 7. å¯¼å…¥å•è¯
        print("\nğŸ“ å¯¼å…¥å•è¯æ•°æ®...")
        importer.import_words(words)
        
        # 8. åˆ›å»ºåŒè¯æ ¹å…³ç³»
        print("\nğŸ”— åˆ›å»ºåŒè¯æ ¹å…³ç³»...")
        importer.create_same_root_relations()
        
        # 9. åˆ›å»ºæ¥¼å±‚
        print("\nğŸ—ï¸ åˆ›å»ºæ¥¼å±‚èŠ‚ç‚¹...")
        importer.create_difficulty_floor_mapping()
        
        # 10. æ˜¾ç¤ºç»Ÿè®¡
        print("\n" + "=" * 60)
        print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡")
        print("=" * 60)
        db_stats = importer.get_statistics()
        print(f"  å•è¯èŠ‚ç‚¹: {db_stats['words']}")
        print(f"  å¹´çº§èŠ‚ç‚¹: {db_stats['grades']}")
        print(f"  è¯æ ¹èŠ‚ç‚¹: {db_stats['roots']}")
        print(f"  å¹´çº§å…³ç³»: {db_stats['belongs_to']}")
        print(f"  è¯æ ¹å…³ç³»: {db_stats['has_root']}")
        print(f"  åŒè¯æ ¹å…³ç³»: {db_stats['same_root']}")
        
        print("\nâœ… æ•°æ®å¯¼å…¥å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        importer.close()


if __name__ == "__main__":
    main()
